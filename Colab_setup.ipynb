{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive\n",
        "\n",
        "Remember to use GPU runtime before mounting your Google Drive. (Runtime --> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCSU4HrvkVDq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n",
        "Replace `Your_Dir` with your own path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gfQ17SmkfOK"
      },
      "outputs": [],
      "source": [
        "cd Your_Dir/emg2qwerty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFFKvhs4tAp5"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n84M6KLmkp2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "164708\n",
            "[2025-03-12 23:46:52,429][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "frequency_shift:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - 1\n",
            "    - -1\n",
            "  batch_dim: 1\n",
            "time_stretch:\n",
            "  _target_: emg2qwerty.transforms.TimeStretch\n",
            "  stretch_factor: 1.2\n",
            "crop:\n",
            "  _target_: emg2qwerty.transforms.RandomCrop\n",
            "  crop_percentage: 0.95\n",
            "random_dropout:\n",
            "  _target_: emg2qwerty.transforms.RandomDropout\n",
            "  dropout_rate: 0.1\n",
            "gaussian_smoothing:\n",
            "  _target_: emg2qwerty.transforms.GaussianSmoothing\n",
            "  kernel_size: 3\n",
            "  sigma: 1.0\n",
            "random_electrode_dropout:\n",
            "  _target_: emg2qwerty.transforms.RandomElectrodeDropout\n",
            "  drop_rate: 0.2\n",
            "random_signal_scaling:\n",
            "  _target_: emg2qwerty.transforms.RandomSignalScaling\n",
            "  scaling_factor_range:\n",
            "  - 0.8\n",
            "  - 1.2\n",
            "fft_transform:\n",
            "  _target_: emg2qwerty.transforms.FFTTransform\n",
            "  n_bins: 256\n",
            "normalize:\n",
            "  _target_: emg2qwerty.transforms.Normalize\n",
            "  mean: 0.01\n",
            "  std: 0.5\n",
            "normalize_per_channel:\n",
            "  _target_: emg2qwerty.transforms.NormalizePerChannel\n",
            "  mean: 0.01\n",
            "  std: 0.5\n",
            "timeWarp:\n",
            "  _target_: emg2qwerty.transforms.TimeWarp\n",
            "  max_warp: 0.1\n",
            "  num_control_points: 5\n",
            "  local_warp_scale: 0.05\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  - ${timeWarp}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvLstmCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.AdamW\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: torch.optim.lr_scheduler.OneCycleLR\n",
            "    max_lr: 0.001\n",
            "    total_steps: 4064\n",
            "    pct_start: 0.3\n",
            "    anneal_strategy: cos\n",
            "    div_factor: 100.0\n",
            "    final_div_factor: 10000.0\n",
            "  interval: step\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-12 23:46:52,435][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvLstmCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-12 23:46:52,558][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /root/emg2qwerty-main/logs/2025-03-12/23-46-52/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 6.9 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "6.9 M     Trainable params\n",
            "0         Non-trainable params\n",
            "6.9 M     Total params\n",
            "27.750    Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:   0%|                                          | 0/127 [00:00<?, ?it/s]/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Epoch 0:  94%|███████████▎| 120/127 [00:36<00:02,  3.26it/s, loss=4.71, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|███████████▍| 121/127 [00:37<00:01,  3.22it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|███████████▌| 122/127 [00:37<00:01,  3.24it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|███████████▌| 123/127 [00:37<00:01,  3.25it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|███████████▋| 124/127 [00:37<00:00,  3.27it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|███████████▊| 125/127 [00:38<00:00,  3.28it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|███████████▉| 126/127 [00:38<00:00,  3.30it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|████████████| 127/127 [00:38<00:00,  3.32it/s, loss=4.71, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|████████████| 127/127 [00:38<00:00,  3.32it/s, loss=4.71, v_num=0]Epoch 0, global step 120: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94%|███████████▎| 120/127 [00:35<00:02,  3.41it/s, loss=3.56, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 121/127 [00:36<00:01,  3.36it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 122/127 [00:36<00:01,  3.38it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▌| 123/127 [00:36<00:01,  3.39it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▋| 124/127 [00:36<00:00,  3.41it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▊| 125/127 [00:36<00:00,  3.42it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▉| 126/127 [00:36<00:00,  3.44it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 127/127 [00:36<00:00,  3.46it/s, loss=3.56, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 127/127 [00:36<00:00,  3.46it/s, loss=3.56, v_num=0]\u001b[AEpoch 1, global step 240: 'val/CER' was not in top 1\n",
            "Epoch 2:  94%|███████████▎| 120/127 [00:36<00:02,  3.33it/s, loss=3.31, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  95%|███████████▍| 121/127 [00:36<00:01,  3.28it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2:  96%|███████████▌| 122/127 [00:36<00:01,  3.30it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2:  97%|███████████▌| 123/127 [00:37<00:01,  3.32it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2:  98%|███████████▋| 124/127 [00:37<00:00,  3.34it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2:  98%|███████████▊| 125/127 [00:37<00:00,  3.35it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2:  99%|███████████▉| 126/127 [00:37<00:00,  3.37it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2: 100%|████████████| 127/127 [00:37<00:00,  3.39it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 2: 100%|████████████| 127/127 [00:37<00:00,  3.39it/s, loss=3.31, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94%|███████████▎| 120/127 [00:37<00:02,  3.22it/s, loss=3.29, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  95%|███████████▍| 121/127 [00:37<00:01,  3.20it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3:  96%|███████████▌| 122/127 [00:37<00:01,  3.22it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3:  97%|███████████▌| 123/127 [00:38<00:01,  3.23it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3:  98%|███████████▋| 124/127 [00:38<00:00,  3.25it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3:  98%|███████████▊| 125/127 [00:38<00:00,  3.27it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3:  99%|███████████▉| 126/127 [00:38<00:00,  3.29it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3: 100%|████████████| 127/127 [00:38<00:00,  3.31it/s, loss=3.29, v_num=0]\u001b[A\n",
            "Epoch 3: 100%|████████████| 127/127 [00:38<00:00,  3.31it/s, loss=3.29, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94%|███████████▎| 120/127 [00:37<00:02,  3.17it/s, loss=3.21, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  95%|███████████▍| 121/127 [00:38<00:01,  3.14it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4:  96%|███████████▌| 122/127 [00:38<00:01,  3.16it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4:  97%|███████████▌| 123/127 [00:38<00:01,  3.18it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4:  98%|███████████▋| 124/127 [00:38<00:00,  3.19it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4:  98%|███████████▊| 125/127 [00:38<00:00,  3.21it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4:  99%|███████████▉| 126/127 [00:39<00:00,  3.23it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4: 100%|████████████| 127/127 [00:39<00:00,  3.25it/s, loss=3.21, v_num=0]\u001b[A\n",
            "Epoch 4: 100%|████████████| 127/127 [00:39<00:00,  3.25it/s, loss=3.21, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94%|███████████▎| 120/127 [00:37<00:02,  3.18it/s, loss=3.07, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  95%|███████████▍| 121/127 [00:38<00:01,  3.14it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5:  96%|███████████▌| 122/127 [00:38<00:01,  3.16it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5:  97%|███████████▌| 123/127 [00:38<00:01,  3.17it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5:  98%|███████████▋| 124/127 [00:38<00:00,  3.19it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5:  98%|███████████▊| 125/127 [00:38<00:00,  3.21it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5:  99%|███████████▉| 126/127 [00:39<00:00,  3.22it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5: 100%|████████████| 127/127 [00:39<00:00,  3.24it/s, loss=3.07, v_num=0]\u001b[A\n",
            "Epoch 5: 100%|████████████| 127/127 [00:39<00:00,  3.24it/s, loss=3.07, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94%|███████████▎| 120/127 [00:38<00:02,  3.16it/s, loss=3.09, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  95%|███████████▍| 121/127 [00:38<00:01,  3.11it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6:  96%|███████████▌| 122/127 [00:39<00:01,  3.13it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6:  97%|███████████▌| 123/127 [00:39<00:01,  3.14it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6:  98%|███████████▋| 124/127 [00:39<00:00,  3.16it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6:  98%|███████████▊| 125/127 [00:39<00:00,  3.18it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6:  99%|███████████▉| 126/127 [00:39<00:00,  3.19it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6: 100%|████████████| 127/127 [00:39<00:00,  3.21it/s, loss=3.09, v_num=0]\u001b[A\n",
            "Epoch 6: 100%|████████████| 127/127 [00:39<00:00,  3.21it/s, loss=3.09, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94%|████████████▎| 120/127 [00:38<00:02,  3.14it/s, loss=2.9, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  95%|████████████▍| 121/127 [00:38<00:01,  3.11it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7:  96%|████████████▍| 122/127 [00:39<00:01,  3.13it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7:  97%|████████████▌| 123/127 [00:39<00:01,  3.14it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7:  98%|████████████▋| 124/127 [00:39<00:00,  3.16it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7:  98%|████████████▊| 125/127 [00:39<00:00,  3.17it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7:  99%|████████████▉| 126/127 [00:39<00:00,  3.19it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7: 100%|█████████████| 127/127 [00:39<00:00,  3.21it/s, loss=2.9, v_num=0]\u001b[A\n",
            "Epoch 7: 100%|█████████████| 127/127 [00:39<00:00,  3.21it/s, loss=2.9, v_num=0]Epoch 7, global step 960: 'val/CER' was not in top 1\n",
            "Epoch 8:  94%|███████████▎| 120/127 [00:38<00:02,  3.13it/s, loss=2.61, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  95%|███████████▍| 121/127 [00:38<00:01,  3.10it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8:  96%|███████████▌| 122/127 [00:39<00:01,  3.12it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8:  97%|███████████▌| 123/127 [00:39<00:01,  3.14it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8:  98%|███████████▋| 124/127 [00:39<00:00,  3.16it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8:  98%|███████████▊| 125/127 [00:39<00:00,  3.17it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8:  99%|███████████▉| 126/127 [00:39<00:00,  3.19it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8: 100%|████████████| 127/127 [00:39<00:00,  3.21it/s, loss=2.61, v_num=0]\u001b[A\n",
            "Epoch 8: 100%|████████████| 127/127 [00:39<00:00,  3.21it/s, loss=2.61, v_num=0]Epoch 8, global step 1080: 'val/CER' reached 99.40186 (best 99.40186), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=8-step=1080.ckpt' as top 1\n",
            "Epoch 9:  94%|███████████▎| 120/127 [00:38<00:02,  3.13it/s, loss=2.32, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  95%|███████████▍| 121/127 [00:39<00:01,  3.09it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9:  96%|███████████▌| 122/127 [00:39<00:01,  3.11it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9:  97%|███████████▌| 123/127 [00:39<00:01,  3.12it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9:  98%|███████████▋| 124/127 [00:39<00:00,  3.14it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9:  98%|███████████▊| 125/127 [00:39<00:00,  3.15it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9:  99%|███████████▉| 126/127 [00:39<00:00,  3.17it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9: 100%|████████████| 127/127 [00:39<00:00,  3.19it/s, loss=2.32, v_num=0]\u001b[A\n",
            "Epoch 9: 100%|████████████| 127/127 [00:39<00:00,  3.18it/s, loss=2.32, v_num=0]Epoch 9, global step 1200: 'val/CER' reached 85.46744 (best 85.46744), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=9-step=1200.ckpt' as top 1\n",
            "Epoch 10:  94%|██████████▍| 120/127 [00:38<00:02,  3.12it/s, loss=2.22, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  95%|██████████▍| 121/127 [00:39<00:01,  3.10it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10:  96%|██████████▌| 122/127 [00:39<00:01,  3.11it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10:  97%|██████████▋| 123/127 [00:39<00:01,  3.13it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10:  98%|██████████▋| 124/127 [00:39<00:00,  3.15it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10:  98%|██████████▊| 125/127 [00:39<00:00,  3.16it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10:  99%|██████████▉| 126/127 [00:39<00:00,  3.18it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10: 100%|███████████| 127/127 [00:39<00:00,  3.20it/s, loss=2.22, v_num=0]\u001b[A\n",
            "Epoch 10: 100%|███████████| 127/127 [00:39<00:00,  3.20it/s, loss=2.22, v_num=0]\u001b[AEpoch 10, global step 1320: 'val/CER' reached 72.95082 (best 72.95082), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=10-step=1320.ckpt' as top 1\n",
            "Epoch 11:  94%|██████████▍| 120/127 [00:38<00:02,  3.11it/s, loss=1.87, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  95%|██████████▍| 121/127 [00:39<00:01,  3.08it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11:  96%|██████████▌| 122/127 [00:39<00:01,  3.10it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11:  97%|██████████▋| 123/127 [00:39<00:01,  3.11it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11:  98%|██████████▋| 124/127 [00:39<00:00,  3.13it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11:  98%|██████████▊| 125/127 [00:39<00:00,  3.15it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11:  99%|██████████▉| 126/127 [00:39<00:00,  3.16it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11: 100%|███████████| 127/127 [00:39<00:00,  3.18it/s, loss=1.87, v_num=0]\u001b[A\n",
            "Epoch 11: 100%|███████████| 127/127 [00:39<00:00,  3.18it/s, loss=1.87, v_num=0]\u001b[AEpoch 11, global step 1440: 'val/CER' reached 52.48117 (best 52.48117), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=11-step=1440.ckpt' as top 1\n",
            "Epoch 12:  94%|██████████▍| 120/127 [00:38<00:02,  3.10it/s, loss=1.81, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  95%|██████████▍| 121/127 [00:39<00:01,  3.08it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12:  96%|██████████▌| 122/127 [00:39<00:01,  3.10it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12:  97%|██████████▋| 123/127 [00:39<00:01,  3.11it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12:  98%|██████████▋| 124/127 [00:39<00:00,  3.13it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12:  98%|██████████▊| 125/127 [00:39<00:00,  3.15it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12:  99%|██████████▉| 126/127 [00:39<00:00,  3.16it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12: 100%|███████████| 127/127 [00:39<00:00,  3.18it/s, loss=1.81, v_num=0]\u001b[A\n",
            "Epoch 12: 100%|███████████| 127/127 [00:39<00:00,  3.18it/s, loss=1.81, v_num=0]Epoch 12, global step 1560: 'val/CER' reached 43.55339 (best 43.55339), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=12-step=1560.ckpt' as top 1\n",
            "Epoch 13:  94%|██████████▍| 120/127 [00:38<00:02,  3.13it/s, loss=1.64, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  95%|██████████▍| 121/127 [00:39<00:01,  3.10it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13:  96%|██████████▌| 122/127 [00:39<00:01,  3.12it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13:  97%|██████████▋| 123/127 [00:39<00:01,  3.13it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13:  98%|██████████▋| 124/127 [00:39<00:00,  3.15it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13:  98%|██████████▊| 125/127 [00:39<00:00,  3.16it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13:  99%|██████████▉| 126/127 [00:39<00:00,  3.18it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13: 100%|███████████| 127/127 [00:39<00:00,  3.19it/s, loss=1.64, v_num=0]\u001b[A\n",
            "Epoch 13: 100%|███████████| 127/127 [00:39<00:00,  3.19it/s, loss=1.64, v_num=0]Epoch 13, global step 1680: 'val/CER' reached 41.91404 (best 41.91404), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=13-step=1680.ckpt' as top 1\n",
            "Epoch 14:  94%|██████████▍| 120/127 [00:38<00:02,  3.14it/s, loss=1.56, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  95%|██████████▍| 121/127 [00:38<00:01,  3.11it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14:  96%|██████████▌| 122/127 [00:39<00:01,  3.13it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14:  97%|██████████▋| 123/127 [00:39<00:01,  3.14it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14:  98%|██████████▋| 124/127 [00:39<00:00,  3.16it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14:  98%|██████████▊| 125/127 [00:39<00:00,  3.18it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14:  99%|██████████▉| 126/127 [00:39<00:00,  3.19it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14: 100%|███████████| 127/127 [00:39<00:00,  3.21it/s, loss=1.56, v_num=0]\u001b[A\n",
            "Epoch 14: 100%|███████████| 127/127 [00:39<00:00,  3.21it/s, loss=1.56, v_num=0]\u001b[AEpoch 14, global step 1800: 'val/CER' was not in top 1\n",
            "Epoch 15:  94%|██████████▍| 120/127 [00:38<00:02,  3.15it/s, loss=1.44, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  95%|██████████▍| 121/127 [00:38<00:01,  3.12it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15:  96%|██████████▌| 122/127 [00:38<00:01,  3.13it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15:  97%|██████████▋| 123/127 [00:39<00:01,  3.15it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15:  98%|██████████▋| 124/127 [00:39<00:00,  3.17it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15:  98%|██████████▊| 125/127 [00:39<00:00,  3.19it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15:  99%|██████████▉| 126/127 [00:39<00:00,  3.20it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=1.44, v_num=0]\u001b[A\n",
            "Epoch 15: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=1.44, v_num=0]Epoch 15, global step 1920: 'val/CER' reached 38.48028 (best 38.48028), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=15-step=1920.ckpt' as top 1\n",
            "Epoch 16:  94%|██████████▍| 120/127 [00:38<00:02,  3.14it/s, loss=1.43, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  95%|██████████▍| 121/127 [00:38<00:01,  3.11it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16:  96%|██████████▌| 122/127 [00:38<00:01,  3.13it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16:  97%|██████████▋| 123/127 [00:39<00:01,  3.15it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16:  98%|██████████▋| 124/127 [00:39<00:00,  3.17it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16:  98%|██████████▊| 125/127 [00:39<00:00,  3.18it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16:  99%|██████████▉| 126/127 [00:39<00:00,  3.20it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=1.43, v_num=0]\u001b[A\n",
            "Epoch 16: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=1.43, v_num=0]\u001b[AEpoch 16, global step 2040: 'val/CER' reached 37.43908 (best 37.43908), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=16-step=2040.ckpt' as top 1\n",
            "Epoch 17:  94%|██████████▍| 120/127 [00:38<00:02,  3.14it/s, loss=1.37, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  95%|██████████▍| 121/127 [00:38<00:01,  3.11it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17:  96%|██████████▌| 122/127 [00:39<00:01,  3.13it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17:  97%|██████████▋| 123/127 [00:39<00:01,  3.14it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17:  98%|██████████▋| 124/127 [00:39<00:00,  3.16it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17:  98%|██████████▊| 125/127 [00:39<00:00,  3.18it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17:  99%|██████████▉| 126/127 [00:39<00:00,  3.20it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=1.37, v_num=0]\u001b[A\n",
            "Epoch 17: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=1.37, v_num=0]Epoch 17, global step 2160: 'val/CER' reached 35.17944 (best 35.17944), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=17-step=2160.ckpt' as top 1\n",
            "Epoch 18:  94%|██████████▍| 120/127 [00:38<00:02,  3.15it/s, loss=1.31, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18:  95%|██████████▍| 121/127 [00:38<00:01,  3.12it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18:  96%|██████████▌| 122/127 [00:38<00:01,  3.14it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18:  97%|██████████▋| 123/127 [00:38<00:01,  3.16it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18:  98%|██████████▋| 124/127 [00:39<00:00,  3.17it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18:  98%|██████████▊| 125/127 [00:39<00:00,  3.19it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18:  99%|██████████▉| 126/127 [00:39<00:00,  3.21it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18: 100%|███████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.31, v_num=0]\u001b[A\n",
            "Epoch 18: 100%|███████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.31, v_num=0]Epoch 18, global step 2280: 'val/CER' reached 34.84714 (best 34.84714), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=18-step=2280.ckpt' as top 1\n",
            "Epoch 19:  94%|██████████▍| 120/127 [00:38<00:02,  3.16it/s, loss=1.41, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  95%|██████████▍| 121/127 [00:38<00:01,  3.13it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19:  96%|██████████▌| 122/127 [00:38<00:01,  3.14it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19:  97%|██████████▋| 123/127 [00:38<00:01,  3.16it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19:  98%|██████████▋| 124/127 [00:39<00:00,  3.18it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19:  98%|██████████▊| 125/127 [00:39<00:00,  3.20it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19:  99%|██████████▉| 126/127 [00:39<00:00,  3.21it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19: 100%|███████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.41, v_num=0]\u001b[A\n",
            "Epoch 19: 100%|███████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.41, v_num=0]\u001b[AEpoch 19, global step 2400: 'val/CER' was not in top 1\n",
            "Epoch 20:  94%|██████████▍| 120/127 [00:37<00:02,  3.16it/s, loss=1.27, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20:  95%|██████████▍| 121/127 [00:38<00:01,  3.13it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20:  96%|██████████▌| 122/127 [00:38<00:01,  3.15it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20:  97%|██████████▋| 123/127 [00:38<00:01,  3.17it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20:  98%|██████████▋| 124/127 [00:38<00:00,  3.19it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20:  98%|██████████▊| 125/127 [00:39<00:00,  3.20it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20:  99%|██████████▉| 126/127 [00:39<00:00,  3.22it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20: 100%|███████████| 127/127 [00:39<00:00,  3.24it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 20: 100%|███████████| 127/127 [00:39<00:00,  3.24it/s, loss=1.27, v_num=0]Epoch 20, global step 2520: 'val/CER' reached 31.96721 (best 31.96721), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=20-step=2520.ckpt' as top 1\n",
            "Epoch 21:  94%|███████████▎| 120/127 [00:38<00:02,  3.16it/s, loss=1.2, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21:  95%|███████████▍| 121/127 [00:38<00:01,  3.13it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21:  96%|███████████▌| 122/127 [00:38<00:01,  3.15it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21:  97%|███████████▌| 123/127 [00:38<00:01,  3.16it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21:  98%|███████████▋| 124/127 [00:38<00:00,  3.18it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21:  98%|███████████▊| 125/127 [00:39<00:00,  3.20it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21:  99%|███████████▉| 126/127 [00:39<00:00,  3.22it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21: 100%|████████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 21: 100%|████████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.2, v_num=0]Epoch 21, global step 2640: 'val/CER' reached 30.50509 (best 30.50509), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=21-step=2640.ckpt' as top 1\n",
            "Epoch 22:  94%|██████████▍| 120/127 [00:37<00:02,  3.16it/s, loss=1.16, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22:  95%|██████████▍| 121/127 [00:38<00:01,  3.13it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22:  96%|██████████▌| 122/127 [00:38<00:01,  3.15it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22:  97%|██████████▋| 123/127 [00:38<00:01,  3.17it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22:  98%|██████████▋| 124/127 [00:38<00:00,  3.18it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22:  98%|██████████▊| 125/127 [00:39<00:00,  3.20it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22:  99%|██████████▉| 126/127 [00:39<00:00,  3.22it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22: 100%|███████████| 127/127 [00:39<00:00,  3.24it/s, loss=1.16, v_num=0]\u001b[A\n",
            "Epoch 22: 100%|███████████| 127/127 [00:39<00:00,  3.24it/s, loss=1.16, v_num=0]Epoch 22, global step 2760: 'val/CER' was not in top 1\n",
            "Epoch 23:  94%|███████████▎| 120/127 [00:38<00:02,  3.13it/s, loss=1.1, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23:  95%|███████████▍| 121/127 [00:38<00:01,  3.11it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23:  96%|███████████▌| 122/127 [00:39<00:01,  3.12it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23:  97%|███████████▌| 123/127 [00:39<00:01,  3.14it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23:  98%|███████████▋| 124/127 [00:39<00:00,  3.16it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23:  98%|███████████▊| 125/127 [00:39<00:00,  3.17it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23:  99%|███████████▉| 126/127 [00:39<00:00,  3.19it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23: 100%|████████████| 127/127 [00:39<00:00,  3.21it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 23: 100%|████████████| 127/127 [00:39<00:00,  3.21it/s, loss=1.1, v_num=0]Epoch 23, global step 2880: 'val/CER' reached 29.97342 (best 29.97342), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=23-step=2880.ckpt' as top 1\n",
            "Epoch 24:  94%|██████████▍| 120/127 [00:37<00:02,  3.17it/s, loss=1.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24:  95%|██████████▍| 121/127 [00:38<00:01,  3.14it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24:  96%|██████████▌| 122/127 [00:38<00:01,  3.16it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24:  97%|██████████▋| 123/127 [00:38<00:01,  3.17it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24:  98%|██████████▋| 124/127 [00:38<00:00,  3.19it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24:  98%|██████████▊| 125/127 [00:39<00:00,  3.20it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24:  99%|██████████▉| 126/127 [00:39<00:00,  3.22it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24: 100%|███████████| 127/127 [00:39<00:00,  3.24it/s, loss=1.04, v_num=0]\u001b[A\n",
            "Epoch 24: 100%|███████████| 127/127 [00:39<00:00,  3.24it/s, loss=1.04, v_num=0]\u001b[AEpoch 24, global step 3000: 'val/CER' reached 28.66637 (best 28.66637), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=24-step=3000.ckpt' as top 1\n",
            "Epoch 25:  94%|██████████▍| 120/127 [00:38<00:02,  3.15it/s, loss=1.01, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25:  95%|██████████▍| 121/127 [00:38<00:01,  3.12it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25:  96%|██████████▌| 122/127 [00:38<00:01,  3.14it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25:  97%|██████████▋| 123/127 [00:38<00:01,  3.16it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25:  98%|██████████▋| 124/127 [00:39<00:00,  3.18it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25:  98%|██████████▊| 125/127 [00:39<00:00,  3.19it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25:  99%|██████████▉| 126/127 [00:39<00:00,  3.21it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25: 100%|███████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.01, v_num=0]\u001b[A\n",
            "Epoch 25: 100%|███████████| 127/127 [00:39<00:00,  3.23it/s, loss=1.01, v_num=0]Epoch 25, global step 3120: 'val/CER' reached 27.58086 (best 27.58086), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=25-step=3120.ckpt' as top 1\n",
            "Epoch 26:  94%|█████████▍| 120/127 [00:38<00:02,  3.16it/s, loss=0.988, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26:  95%|█████████▌| 121/127 [00:38<00:01,  3.12it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26:  96%|█████████▌| 122/127 [00:38<00:01,  3.14it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26:  97%|█████████▋| 123/127 [00:39<00:01,  3.15it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26:  98%|█████████▊| 124/127 [00:39<00:00,  3.17it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26:  98%|█████████▊| 125/127 [00:39<00:00,  3.18it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26:  99%|█████████▉| 126/127 [00:39<00:00,  3.20it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26: 100%|██████████| 127/127 [00:39<00:00,  3.21it/s, loss=0.988, v_num=0]\u001b[A\n",
            "Epoch 26: 100%|██████████| 127/127 [00:39<00:00,  3.21it/s, loss=0.988, v_num=0]Epoch 26, global step 3240: 'val/CER' was not in top 1\n",
            "Epoch 27:  94%|█████████▍| 120/127 [00:38<00:02,  3.14it/s, loss=0.982, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27:  95%|█████████▌| 121/127 [00:38<00:01,  3.11it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27:  96%|█████████▌| 122/127 [00:39<00:01,  3.12it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27:  97%|█████████▋| 123/127 [00:39<00:01,  3.14it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27:  98%|█████████▊| 124/127 [00:39<00:00,  3.15it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27:  98%|█████████▊| 125/127 [00:39<00:00,  3.17it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27:  99%|█████████▉| 126/127 [00:39<00:00,  3.18it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27: 100%|██████████| 127/127 [00:39<00:00,  3.20it/s, loss=0.982, v_num=0]\u001b[A\n",
            "Epoch 27: 100%|██████████| 127/127 [00:39<00:00,  3.20it/s, loss=0.982, v_num=0]Epoch 27, global step 3360: 'val/CER' reached 26.82765 (best 26.82765), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=27-step=3360.ckpt' as top 1\n",
            "Epoch 28:  94%|██████████▍| 120/127 [00:38<00:02,  3.14it/s, loss=0.96, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28:  95%|██████████▍| 121/127 [00:38<00:01,  3.12it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28:  96%|██████████▌| 122/127 [00:38<00:01,  3.14it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28:  97%|██████████▋| 123/127 [00:39<00:01,  3.15it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28:  98%|██████████▋| 124/127 [00:39<00:00,  3.17it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28:  98%|██████████▊| 125/127 [00:39<00:00,  3.19it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28:  99%|██████████▉| 126/127 [00:39<00:00,  3.20it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=0.96, v_num=0]\u001b[A\n",
            "Epoch 28: 100%|███████████| 127/127 [00:39<00:00,  3.22it/s, loss=0.96, v_num=0]\u001b[AEpoch 28, global step 3480: 'val/CER' reached 26.11874 (best 26.11874), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=28-step=3480.ckpt' as top 1\n",
            "Epoch 29:  94%|█████████▍| 120/127 [00:38<00:02,  3.15it/s, loss=0.947, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29:  95%|█████████▌| 121/127 [00:38<00:01,  3.12it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29:  96%|█████████▌| 122/127 [00:38<00:01,  3.14it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29:  97%|█████████▋| 123/127 [00:38<00:01,  3.16it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29:  98%|█████████▊| 124/127 [00:39<00:00,  3.18it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29:  98%|█████████▊| 125/127 [00:39<00:00,  3.19it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29:  99%|█████████▉| 126/127 [00:39<00:00,  3.21it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29: 100%|██████████| 127/127 [00:39<00:00,  3.23it/s, loss=0.947, v_num=0]\u001b[A\n",
            "Epoch 29: 100%|██████████| 127/127 [00:39<00:00,  3.23it/s, loss=0.947, v_num=0]Epoch 29, global step 3600: 'val/CER' reached 25.18830 (best 25.18830), saving model to '/root/emg2qwerty-main/logs/2025-03-12/23-46-52/checkpoints/epoch=29-step=3600.ckpt' as top 1\n",
            "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
            "Epoch 29: 100%|██████████| 127/127 [00:39<00:00,  3.21it/s, loss=0.947, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00,  9.84it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Runningstage.validating metric      DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            25.188302993774414\n",
            "         val/DER            3.9432876110076904\n",
            "         val/IER             6.845369815826416\n",
            "         val/SER            14.399645805358887\n",
            "        val/loss            0.7874048948287964\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  16762 KiB |   2566 MiB |  36763 GiB |  36763 GiB |\n",
            "|       from large pool |  16761 KiB |   2548 MiB |  36671 GiB |  36671 GiB |\n",
            "|       from small pool |      0 KiB |     23 MiB |     91 GiB |     91 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  16762 KiB |   2566 MiB |  36763 GiB |  36763 GiB |\n",
            "|       from large pool |  16761 KiB |   2548 MiB |  36671 GiB |  36671 GiB |\n",
            "|       from small pool |      0 KiB |     23 MiB |     91 GiB |     91 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |  16640 KiB |   2560 MiB |  36712 GiB |  36712 GiB |\n",
            "|       from large pool |  16640 KiB |   2543 MiB |  36621 GiB |  36621 GiB |\n",
            "|       from small pool |      0 KiB |     23 MiB |     91 GiB |     91 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   | 112640 KiB |   3346 MiB |   4442 MiB |   4332 MiB |\n",
            "|       from large pool | 110592 KiB |   3320 MiB |   4402 MiB |   4294 MiB |\n",
            "|       from small pool |   2048 KiB |     26 MiB |     40 MiB |     38 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  95878 KiB |   1201 MiB |  27936 GiB |  27936 GiB |\n",
            "|       from large pool |  93830 KiB |   1198 MiB |  27836 GiB |  27835 GiB |\n",
            "|       from small pool |   2047 KiB |      9 MiB |    100 GiB |    100 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       3    |     417    |    1499 K  |    1499 K  |\n",
            "|       from large pool |       2    |      79    |     734 K  |     734 K  |\n",
            "|       from small pool |       1    |     366    |     764 K  |     764 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       3    |     417    |    1499 K  |    1499 K  |\n",
            "|       from large pool |       2    |      79    |     734 K  |     734 K  |\n",
            "|       from small pool |       1    |     366    |     764 K  |     764 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       3    |      45    |      62    |      59    |\n",
            "|       from large pool |       2    |      32    |      42    |      40    |\n",
            "|       from small pool |       1    |      13    |      20    |      19    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       5    |      52    |  746579    |  746574    |\n",
            "|       from large pool |       3    |      27    |  421558    |  421555    |\n",
            "|       from small pool |       2    |      30    |  325021    |  325019    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 0it [00:00, ?it/s]Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/queue.py\", line 179, in get\n",
            "    raise Empty\n",
            "_queue.Empty\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/emg2qwerty-main/emg2qwerty/train.py\", line 131, in main\n",
            "    test_metrics = trainer.test(module, datamodule)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 121, in advance\n",
            "    batch = next(data_fetcher)\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1146, in _try_get_data\n",
            "    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e\n",
            "RuntimeError: DataLoader worker (pid(s) 168358) exited unexpectedly\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "Testing: 0it [00:15, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- Replace `Your_Path_to_Checkpoint` with your checkpoint path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python: can't open file '/root/emg2qwerty-main/emg2qwerty.hyperparameter_search': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter search\n",
        "!python emg2qwerty.hyperparameter_search \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1\n",
        "  #hyperparameter lmao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p68aDt-8pmGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/root/emg2qwerty-main/emg2qwerty/train.py\", line 21, in <module>\n",
            "    from emg2qwerty import transforms, utils\n",
            "  File \"/root/emg2qwerty-main/emg2qwerty/transforms.py\", line 14, in <module>\n",
            "    import torchaudio\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torchaudio/__init__.py\", line 13, in <module>\n",
            "    from . import (  # noqa: F401\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torchaudio/models/__init__.py\", line 18, in <module>\n",
            "    from .wav2vec2 import (\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torchaudio/models/wav2vec2/__init__.py\", line 1, in <module>\n",
            "    from . import utils\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1032, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1130, in get_data\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint='bestCheckpoints/bruh.ckpt' \\\n",
        "  train=False  trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \n",
        "  # --multirun"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
