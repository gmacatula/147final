{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive\n",
        "\n",
        "Remember to use GPU runtime before mounting your Google Drive. (Runtime --> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCSU4HrvkVDq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n",
        "Replace `Your_Dir` with your own path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gfQ17SmkfOK"
      },
      "outputs": [],
      "source": [
        "cd Your_Dir/emg2qwerty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFFKvhs4tAp5"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "n84M6KLmkp2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Mar 12 01:19:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 565.72                 Driver Version: 566.14         CUDA Version: 12.7     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4060 ...    On  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   50C    P8              2W /   85W |       3MiB /   8188MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "[2025-03-12 01:19:13,057][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "frequency_shift:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - 1\n",
            "    - -1\n",
            "  batch_dim: 1\n",
            "time_stretch:\n",
            "  _target_: emg2qwerty.transforms.TimeStretch\n",
            "  stretch_factor: 1.2\n",
            "crop:\n",
            "  _target_: emg2qwerty.transforms.RandomCrop\n",
            "  crop_percentage: 0.95\n",
            "random_dropout:\n",
            "  _target_: emg2qwerty.transforms.RandomDropout\n",
            "  dropout_rate: 0.1\n",
            "gaussian_smoothing:\n",
            "  _target_: emg2qwerty.transforms.GaussianSmoothing\n",
            "  kernel_size: 3\n",
            "  sigma: 1.0\n",
            "random_electrode_dropout:\n",
            "  _target_: emg2qwerty.transforms.RandomElectrodeDropout\n",
            "  drop_rate: 0.2\n",
            "random_signal_scaling:\n",
            "  _target_: emg2qwerty.transforms.RandomSignalScaling\n",
            "  scaling_factor_range:\n",
            "  - 0.8\n",
            "  - 1.2\n",
            "fft_transform:\n",
            "  _target_: emg2qwerty.transforms.FFTTransform\n",
            "  n_bins: 256\n",
            "normalize:\n",
            "  _target_: emg2qwerty.transforms.Normalize\n",
            "  mean: 0.01\n",
            "  std: 0.5\n",
            "normalize_per_channel:\n",
            "  _target_: emg2qwerty.transforms.NormalizePerChannel\n",
            "  mean: 0.01\n",
            "  std: 0.5\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 1\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-12 01:19:13,064][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-12 01:19:13,159][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /root/emg2qwerty-main/logs/2025-03-12/01-19-12/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 5.3 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "5.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.3 M     Total params\n",
            "21.173    Total estimated model params size (MB)\n",
            "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Epoch 0:   0%|                                          | 0/127 [00:00<?, ?it/s]/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "Epoch 0:  94%|████████████▎| 120/127 [00:33<00:01,  3.53it/s, loss=122, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|████████████▍| 121/127 [00:34<00:01,  3.49it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▍| 122/127 [00:34<00:01,  3.51it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▌| 123/127 [00:34<00:01,  3.53it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▋| 124/127 [00:34<00:00,  3.55it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▊| 125/127 [00:35<00:00,  3.56it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▉| 126/127 [00:35<00:00,  3.58it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 127/127 [00:35<00:00,  3.60it/s, loss=122, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 127/127 [00:35<00:00,  3.60it/s, loss=122, v_num=0]Epoch 0, global step 120: 'val/CER' reached 1358.19678 (best 1358.19678), saving model to '/root/emg2qwerty-main/logs/2025-03-12/01-19-12/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
            "Epoch 0: 100%|█████████████| 127/127 [00:35<00:00,  3.57it/s, loss=122, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00,  9.70it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Runningstage.validating metric      DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER             1358.19677734375\n",
            "         val/DER            1294.3287353515625\n",
            "         val/IER                    0.0\n",
            "         val/SER             63.86796569824219\n",
            "        val/loss            101.53596496582031\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 0it [00:00, ?it/s]Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1']\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/queue.py\", line 179, in get\n",
            "    raise Empty\n",
            "_queue.Empty\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/root/emg2qwerty-main/emg2qwerty/train.py\", line 128, in main\n",
            "    test_metrics = trainer.test(module, datamodule)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "              ^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 121, in advance\n",
            "    batch = next(data_fetcher)\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "                ^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1285, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "                    ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1146, in _try_get_data\n",
            "    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e\n",
            "RuntimeError: DataLoader worker (pid(s) 168993) exited unexpectedly\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
            "Testing: 0it [00:05, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "# Single-user training\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- Replace `Your_Path_to_Checkpoint` with your checkpoint path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python: can't open file '/root/emg2qwerty-main/emg2qwerty.hyperparameter_search': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameter search\n",
        "!python emg2qwerty.hyperparameter_search \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1\n",
        "  #hyperparameter lmao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p68aDt-8pmGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-11 20:37:08,287][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "frequency_shift:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - 1\n",
            "    - -1\n",
            "  batch_dim: 1\n",
            "time_stretch:\n",
            "  _target_: emg2qwerty.transforms.TimeStretch\n",
            "  stretch_factor: 1.2\n",
            "crop:\n",
            "  _target_: emg2qwerty.transforms.RandomCrop\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  - ${time_stretch}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: false\n",
            "checkpoint: bestCheckpoints/bestBaseline.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 30\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-11 20:37:08,288][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-11 20:37:08,340][__main__][INFO] - Loading module from checkpoint bestCheckpoints/bestBaseline.ckpt\n",
            "[2025-03-11 20:37:08,470][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /root/emg2qwerty-main/logs/2025-03-11/20-37-08/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]/root/emg2qwerty-main/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00,  7.34it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Runningstage.validating metric      DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            27.603012084960938\n",
            "         val/DER            1.7722641229629517\n",
            "         val/IER             9.45945930480957\n",
            "         val/SER             16.37129020690918\n",
            "        val/loss            0.8916577100753784\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:05<00:00,  5.01s/it]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "Runningstage.testing metric      DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "        test/CER               28.052734375\n",
            "        test/DER            1.9234925508499146\n",
            "        test/IER             7.564296722412109\n",
            "        test/SER            18.564945220947266\n",
            "        test/loss           0.9024567604064941\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "{'val_metrics': [{'val/loss': 0.8916577100753784,\n",
            "                  'val/CER': 27.603012084960938,\n",
            "                  'val/IER': 9.45945930480957,\n",
            "                  'val/DER': 1.7722641229629517,\n",
            "                  'val/SER': 16.37129020690918}],\n",
            " 'test_metrics': [{'test/loss': 0.9024567604064941,\n",
            "                   'test/CER': 28.052734375,\n",
            "                   'test/IER': 7.564296722412109,\n",
            "                   'test/DER': 1.9234925508499146,\n",
            "                   'test/SER': 18.564945220947266}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint='bestCheckpoints/bestBaseline.ckpt' \\\n",
        "  train=False  trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \n",
        "  # --multirun"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
